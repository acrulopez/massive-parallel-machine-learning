{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelized version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c0f4ca9fab84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"appName\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1669673861382'),\n",
       " ('spark.driver.port', '39653'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.name', 'appName'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.driver.host', '10.0.2.15'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(dataset):\n",
    "    train = dataset.filter(lambda x: x[2]==1)\n",
    "    train = train.map(lambda x: (x[0], x[1]))\n",
    "    test = dataset.filter(lambda x: x[2]==0)\n",
    "    test = test.map(lambda x: (x[0], x[1]))\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_cost_function(RDD_Xyyhat, lambda_ref, m, w):\n",
    "    y = RDD_Xyyhat[1]\n",
    "    y_hat = RDD_Xyyhat[2]\n",
    "    temp = (-1/m) * (\n",
    "        y * np.log(y_hat) + (1 - y)\n",
    "        * np.log(1 - y_hat)\n",
    "    )\n",
    "    cost = temp + (lambda_ref/(2*m))*sum([i*i for i in w.value])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_number_list(line):\n",
    "    numbers = line.replace(\" \",\"\").split(\",\")\n",
    "    numbers = [float(number) for number in numbers]\n",
    "    \n",
    "    # Separate X and y\n",
    "    numbers = (numbers[:-1], numbers[-1])\n",
    "    \n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_list_values(list1, list2):\n",
    "    return [n1 + n2 for n1, n2 in zip(list1, list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_minus_mean_squared(numbers):\n",
    "    return [(number-means.value[x])**2 for x,number in enumerate(numbers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_mean_by_column(RDD_Xy, m):\n",
    "    means = RDD_Xy.map(lambda x: x[0]).reduce(sum_list_values)\n",
    "    means = [x/m for x in means]\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_mean_by_column(RDD_Xy, m):\n",
    "    means = RDD_Xy.map(lambda x: x[0]).reduce(sum_list_values)\n",
    "    means = [x/m for x in means]\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_std_by_column(RDD_Xy, m):\n",
    "    stds = RDD_Xy.map(lambda x: x[0]).map(sum_minus_mean_squared).reduce(sum_list_values)\n",
    "    stds = [math.sqrt(x/m) for x in stds]\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_RDDXy_by_w(Xy):\n",
    "    global b\n",
    "    tot = 0\n",
    "    for xi, wi in zip(Xy[0], w.value):\n",
    "        tot += xi * wi\n",
    "    tot += b\n",
    "    return (Xy[0], Xy[1], sigmoid(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dw(RDD_Xyyhat):\n",
    "    dw = []\n",
    "    for x in RDD_Xyyhat[0]:\n",
    "        dw.append((RDD_Xyyhat[2]-RDD_Xyyhat[1])*x)\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mandatory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    dataset = sc.textFile(filename)\n",
    "    dataset = dataset.map(str_to_number_list)\n",
    "    return dataset.sample(False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(RDD_Xy):\n",
    "    m = RDD_Xy.count()\n",
    "    global means\n",
    "    means = sc.broadcast(rdd_mean_by_column(RDD_Xy, m))\n",
    "    stds = sc.broadcast(rdd_std_by_column(RDD_Xy, m))\n",
    "    norm_rdd = RDD_Xy.map(lambda values: ([(x - mean) / std for x, mean, std in zip(values[0], means.value, stds.value)], values[1]))\n",
    "    return norm_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(RDD_Xy, iterations, learning_rate, lambda_reg):\n",
    "    global b\n",
    "    global m\n",
    "    m = RDD_Xy.count()\n",
    "    n = len(RDD_Xy.take(1)[0][0])\n",
    "    global w\n",
    "    w_temp = w.value.copy()\n",
    "    for it in range(iterations):\n",
    "        RDD_Xyyhat = RDD_Xy.map(multiply_RDDXy_by_w)\n",
    "        print(f\"Cost for it {it}:\", RDD_Xyyhat.map(lambda x: rdd_cost_function(x, lambda_reg, m, w)).reduce(lambda x,y: x+y))\n",
    "        dw=[0 for i in range(0,n)]\n",
    "        for cl in range(n):\n",
    "                X_cl = RDD_Xyyhat.map(lambda x: (x[2]-x[1])*x[0][cl]).reduce(lambda x, y: x+y)\n",
    "                dw[cl] = (1/m)*(X_cl)+(lambda_reg/m)*w_temp[cl]\n",
    "                w_temp[cl] -= learning_rate * dw[cl]\n",
    "        w = sc.broadcast(w_temp)\n",
    "        db = (1/m)*RDD_Xyyhat.map(lambda x: x[2]-x[1]).reduce(lambda x, y: x+y)\n",
    "        b -= learning_rate * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPrediction(y, y_hat):\n",
    "    if (y == y_hat and y_hat==0):\n",
    "        return (0, 1, 0, 0)\n",
    "    if (y == y_hat and y_hat==1):\n",
    "        return (1, 0, 0, 0)\n",
    "    if (y != y_hat and y_hat==1):\n",
    "        return (0, 0, 1, 0)\n",
    "    if (y != y_hat and y_hat==0):\n",
    "        return (0,0,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(ws, b, RDD_Xy, treshold=0.5):\n",
    "    total = RDD_Xy.count()\n",
    "    y_and_y_hat = RDD_Xy.map(lambda x: (x[1], predict_with_teshold(ws, x[0], b, treshold)))\n",
    "    result = y_and_y_hat.map(lambda x: checkPrediction(x[0], x[1]))\n",
    "    \n",
    "    tp = result.map(lambda x: x[0]).reduce(lambda x,y: x+y)\n",
    "    tn = result.map(lambda x: x[1]).reduce(lambda x,y: x+y)\n",
    "    fp = result.map(lambda x: x[2]).reduce(lambda x,y: x+y)\n",
    "    fn = result.map(lambda x: x[3]).reduce(lambda x,y: x+y)\n",
    "    acc = (tp+tn)/total\n",
    "    \n",
    "    tpr = tp/(tp+fn)\n",
    "    fpr = fp/(fp+tn)\n",
    "    \n",
    "    return acc, tp, tn, fp, fn, tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ws, b, RDD_Xy):\n",
    "    total = RDD_Xy.count()\n",
    "    y_and_y_hat = RDD_Xy.map(lambda x: (x[1], predict(ws, x[0], b)))\n",
    "    result = y_and_y_hat.map(lambda x: checkPrediction(x[0], x[1]))\n",
    "    tp = result.map(lambda x: x[0]).reduce(lambda x,y: x+y)\n",
    "    tn = result.map(lambda x: x[1]).reduce(lambda x,y: x+y)\n",
    "    fp = result.map(lambda x: x[2]).reduce(lambda x,y: x+y)\n",
    "    fn = result.map(lambda x: x[3]).reduce(lambda x,y: x+y)\n",
    "    acc = (tp+tn)/total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, X, b):\n",
    "    tot = 0\n",
    "    for xi, wi in zip(X, w.value):\n",
    "        tot += xi * wi\n",
    "    tot += b\n",
    "    val = sigmoid(tot)\n",
    "    if (val>=0.5):\n",
    "        return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_teshold(w, X, b, tresh):\n",
    "    tot = 0\n",
    "    for xi, wi in zip(X, w.value):\n",
    "        tot += xi * wi\n",
    "    tot += b\n",
    "    val = sigmoid(tot)\n",
    "    if (val>=tresh):\n",
    "        return 1.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD_Xy = readFile(\"../data/botnet_tot_syn_l.csv\")\n",
    "RDD_Xy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RDD_Xy_normalized = normalize(RDD_Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_Xy_presplit = RDD_Xy_normalized.map(lambda x: (x[0], x[1], 1 if random.random() < 0.75 else 0))\n",
    "train_data, test_data = trainTestSplit(RDD_Xy_presplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize some stuff before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "\n",
    "global b  \n",
    "b = 0\n",
    "\n",
    "global n\n",
    "n = len(RDD_Xy.take(1)[0][0])\n",
    "\n",
    "global w\n",
    "w = sc.broadcast(np.random.rand(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost for it 0: 1.44408436422267\n",
      "Cost for it 1: 0.7354116040444414\n",
      "Cost for it 2: 0.4503747259011286\n",
      "Cost for it 3: 0.34535318105954693\n",
      "Cost for it 4: 0.29726803973963817\n",
      "Cost for it 5: 0.26944799866353875\n",
      "Cost for it 6: 0.251485793408003\n",
      "Cost for it 7: 0.23888376813319226\n",
      "Cost for it 8: 0.22943385362889546\n",
      "Cost for it 9: 0.2217561774658017\n"
     ]
    }
   ],
   "source": [
    "w_final, b = train(train_data, 10, 1.5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy(w_final, b, test_data)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment to get the different datapoints for roc and precision-recall curve\n",
    "treshold = 0.00\n",
    "x = []\n",
    "y = []\n",
    "while treshold <= 1:\n",
    "    acc, tp, tn, fp, fn, tpr, fpr = metrics(w_final, b, test_data, treshold)\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    x.append(precision)\n",
    "    y.append(recall)\n",
    "    treshold += 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_times = {}\n",
    "\n",
    "for cores in range(1,13,1):\n",
    "    sc.stop()\n",
    "    conf = SparkConf().setAppName(\"appName\").setMaster(f\"local[{cores}]\")\n",
    "    sc = SparkContext(conf=conf)\n",
    "    \n",
    "    print(f\"---------- Starting execution with {cores} cores ----------\")\n",
    "    \n",
    "    \n",
    "    # ---------- Execution ----------\n",
    "    RDD_Xy = readFile(\"../data/botnet_tot_syn_l.csv\")\n",
    "    RDD_Xy_normalized = normalize(RDD_Xy)\n",
    "    RDD_Xy_presplit = RDD_Xy_normalized.map(lambda x: (x[0], x[1], 1 if random.random() < 0.75 else 0))\n",
    "    train_data, test_data = trainTestSplit(RDD_Xy_presplit)\n",
    "    start = time.time()\n",
    "    \n",
    "    np.random.seed(33)\n",
    "    global b  \n",
    "    b = 0\n",
    "    global n\n",
    "    n = len(RDD_Xy.take(1)[0][0])\n",
    "    global w\n",
    "    w = sc.broadcast(np.random.rand(n))\n",
    "    w_final, b = train(train_data, 10, 1.5, 0)\n",
    "    acc, tp, tn, fp, fn = accuracy(w_final, b, test_data)\n",
    "    print(f\"The accuracy for the test set is: {acc}\")\n",
    "    total = tp+tn+fp+fn\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    print(f\"The accuracy for the test set is: {acc}\")\n",
    "    print(f\"The tp percentage is: {tp/total}\")\n",
    "    print(f\"The tn percentage is: {tn/total}\")\n",
    "    print(f\"The fp percentage is: {fp/total}\")\n",
    "    print(f\"The fn percentage is: {fn/total}\")\n",
    "    print(f\"The precision is: {precision}\")\n",
    "    print(f\"The recall is: {recall}\")\n",
    "    print(f\"The f1 score is: {f1}\")\n",
    "    # ---------- Execution ----------\n",
    "\n",
    "    end = time.time()\n",
    "    print(f\"---------- Finished execution with {cores} cores ----------\")\n",
    "    elapsed_time = end - start\n",
    "    elapsed_times[cores] = elapsed_time\n",
    "    print(f\"Elapsed time for cores {cores} is {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
